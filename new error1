Fetching 3 files: 100% 3/3 [01:14<00:00, 24.70s/it]
Loading checkpoint shards:  67% 2/3 [00:04<00:02,  2.29s/it]
2025-08-20 09:56:22 | ERROR | hf-local | [hf_local] Preferred load failed, trying device_map='auto': CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py:1582: UserWarning: Current model requires 64 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.
  warnings.warn(
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
2025-08-20 09:56:22 | ERROR | hf-local | [hf_local] device_map='auto' failed, falling back to CPU: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 159, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 114, in convert_moe_packed_tensors
    out = torch.empty(rows_total, B * 2, dtype=dtype, device=blocks.device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]

[2/7] Testing: Reward Hacking via Confidence Gaming
2025-08-20 09:56:23 | INFO | hf-local | [hf_local] Loading tokenizer: openai/gpt-oss-20b
2025-08-20 09:56:24 | ERROR | hf-local | [hf_local] 8-bit load failed; falling back to non-quantized path: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 96, in start
    self._model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 4873, in from_pretrained
    config.quantization_config = AutoHfQuantizer.merge_quantization_configs(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py", line 224, in merge_quantization_configs
    loading_attr_dict = quantization_config_from_args.get_loading_attributes()
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
2025-08-20 09:56:24 | INFO | hf-local | [hf_local] Attempting preferred load: device_map='cuda', torch_dtype='auto'
Loading checkpoint shards:  67% 2/3 [00:04<00:02,  2.27s/it]
2025-08-20 09:56:29 | ERROR | hf-local | [hf_local] Preferred load failed, trying device_map='auto': CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 370.88 MiB is free. Process 34557 has 39.19 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 88.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 370.88 MiB is free. Process 34557 has 39.19 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 88.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
2025-08-20 09:56:30 | ERROR | hf-local | [hf_local] device_map='auto' failed, falling back to CPU: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 190.88 MiB is free. Process 34557 has 39.36 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 109.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 370.88 MiB is free. Process 34557 has 39.19 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 88.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 159, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 114, in convert_moe_packed_tensors
    out = torch.empty(rows_total, B * 2, dtype=dtype, device=blocks.device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 190.88 MiB is free. Process 34557 has 39.36 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 109.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]

[3/7] Testing: Chain-of-Thought Manipulation
2025-08-20 09:56:30 | INFO | hf-local | [hf_local] Loading tokenizer: openai/gpt-oss-20b
2025-08-20 09:56:32 | ERROR | hf-local | [hf_local] 8-bit load failed; falling back to non-quantized path: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 96, in start
    self._model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 4873, in from_pretrained
    config.quantization_config = AutoHfQuantizer.merge_quantization_configs(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py", line 224, in merge_quantization_configs
    loading_attr_dict = quantization_config_from_args.get_loading_attributes()
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
2025-08-20 09:56:32 | INFO | hf-local | [hf_local] Attempting preferred load: device_map='cuda', torch_dtype='auto'
Loading checkpoint shards:  67% 2/3 [00:04<00:02,  2.12s/it]
2025-08-20 09:56:36 | ERROR | hf-local | [hf_local] Preferred load failed, trying device_map='auto': CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 370.88 MiB is free. Process 34557 has 39.19 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 88.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 370.88 MiB is free. Process 34557 has 39.19 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 88.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
2025-08-20 09:56:37 | ERROR | hf-local | [hf_local] device_map='auto' failed, falling back to CPU: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 370.88 MiB is free. Process 34557 has 39.19 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 88.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 159, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 114, in convert_moe_packed_tensors
    out = torch.empty(rows_total, B * 2, dtype=dtype, device=blocks.device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]

[4/7] Testing: Evaluation Awareness Test
2025-08-20 09:56:37 | INFO | hf-local | [hf_local] Loading tokenizer: openai/gpt-oss-20b
2025-08-20 09:56:39 | ERROR | hf-local | [hf_local] 8-bit load failed; falling back to non-quantized path: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 96, in start
    self._model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 4873, in from_pretrained
    config.quantization_config = AutoHfQuantizer.merge_quantization_configs(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py", line 224, in merge_quantization_configs
    loading_attr_dict = quantization_config_from_args.get_loading_attributes()
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
2025-08-20 09:56:39 | INFO | hf-local | [hf_local] Attempting preferred load: device_map='cuda', torch_dtype='auto'
Loading checkpoint shards:  67% 2/3 [00:04<00:02,  2.10s/it]
2025-08-20 09:56:44 | ERROR | hf-local | [hf_local] Preferred load failed, trying device_map='auto': CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
2025-08-20 09:56:44 | ERROR | hf-local | [hf_local] device_map='auto' failed, falling back to CPU: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 190.88 MiB is free. Process 34557 has 39.36 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 109.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 159, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 114, in convert_moe_packed_tensors
    out = torch.empty(rows_total, B * 2, dtype=dtype, device=blocks.device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 190.88 MiB is free. Process 34557 has 39.36 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 109.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]

[5/7] Testing: Tool Use Exploitation
2025-08-20 09:56:44 | INFO | hf-local | [hf_local] Loading tokenizer: openai/gpt-oss-20b
2025-08-20 09:56:46 | ERROR | hf-local | [hf_local] 8-bit load failed; falling back to non-quantized path: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 96, in start
    self._model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 4873, in from_pretrained
    config.quantization_config = AutoHfQuantizer.merge_quantization_configs(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py", line 224, in merge_quantization_configs
    loading_attr_dict = quantization_config_from_args.get_loading_attributes()
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
2025-08-20 09:56:46 | INFO | hf-local | [hf_local] Attempting preferred load: device_map='cuda', torch_dtype='auto'
Loading checkpoint shards:  67% 2/3 [00:04<00:02,  2.10s/it]
2025-08-20 09:56:51 | ERROR | hf-local | [hf_local] Preferred load failed, trying device_map='auto': CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
2025-08-20 09:56:51 | ERROR | hf-local | [hf_local] device_map='auto' failed, falling back to CPU: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 159, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 114, in convert_moe_packed_tensors
    out = torch.empty(rows_total, B * 2, dtype=dtype, device=blocks.device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]

[6/7] Testing: Data Exfiltration via Encoding
2025-08-20 09:56:52 | INFO | hf-local | [hf_local] Loading tokenizer: openai/gpt-oss-20b
2025-08-20 09:56:54 | ERROR | hf-local | [hf_local] 8-bit load failed; falling back to non-quantized path: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 96, in start
    self._model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 4873, in from_pretrained
    config.quantization_config = AutoHfQuantizer.merge_quantization_configs(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py", line 224, in merge_quantization_configs
    loading_attr_dict = quantization_config_from_args.get_loading_attributes()
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
2025-08-20 09:56:54 | INFO | hf-local | [hf_local] Attempting preferred load: device_map='cuda', torch_dtype='auto'
Loading checkpoint shards:  67% 2/3 [00:04<00:02,  2.10s/it]
2025-08-20 09:56:58 | ERROR | hf-local | [hf_local] Preferred load failed, trying device_map='auto': CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 350.88 MiB is free. Process 34557 has 39.21 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 108.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 350.88 MiB is free. Process 34557 has 39.21 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 108.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
2025-08-20 09:56:59 | ERROR | hf-local | [hf_local] device_map='auto' failed, falling back to CPU: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 190.88 MiB is free. Process 34557 has 39.36 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 109.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 350.88 MiB is free. Process 34557 has 39.21 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 108.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 159, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 114, in convert_moe_packed_tensors
    out = torch.empty(rows_total, B * 2, dtype=dtype, device=blocks.device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 190.88 MiB is free. Process 34557 has 39.36 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 109.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]

[7/7] Testing: Sandbagging Capability Test
2025-08-20 09:56:59 | INFO | hf-local | [hf_local] Loading tokenizer: openai/gpt-oss-20b
2025-08-20 09:57:01 | ERROR | hf-local | [hf_local] 8-bit load failed; falling back to non-quantized path: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 96, in start
    self._model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 4873, in from_pretrained
    config.quantization_config = AutoHfQuantizer.merge_quantization_configs(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py", line 224, in merge_quantization_configs
    loading_attr_dict = quantization_config_from_args.get_loading_attributes()
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'
2025-08-20 09:57:01 | INFO | hf-local | [hf_local] Attempting preferred load: device_map='cuda', torch_dtype='auto'
Loading checkpoint shards:  67% 2/3 [00:04<00:02,  2.12s/it]
2025-08-20 09:57:05 | ERROR | hf-local | [hf_local] Preferred load failed, trying device_map='auto': CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
2025-08-20 09:57:06 | ERROR | hf-local | [hf_local] device_map='auto' failed, falling back to CPU: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 141, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 127, in convert_moe_packed_tensors
    sub[:, 0::2] = lut[idx_lo]
                   ~~~^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 390.88 MiB is free. Process 34557 has 39.17 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 68.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/content/kaggleproject/src/backends/hf_local.py", line 159, in start
    self._model = AutoModelForCausalLM.from_pretrained(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5069, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 5532, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py", line 883, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(
  File "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_mxfp4.py", line 247, in create_quantized_param
    dequantize(module, param_name, param_value, target_device, dq_param_name, **shard_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 342, in dequantize
    dequantized = convert_moe_packed_tensors(getattr(module, blocks_attr), getattr(module, scales_attr))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/integrations/mxfp4.py", line 114, in convert_moe_packed_tensors
    out = torch.empty(rows_total, B * 2, dtype=dtype, device=blocks.device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 230.88 MiB is free. Process 34557 has 39.32 GiB memory in use. Of the allocated memory 38.78 GiB is allocated by PyTorch, and 69.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]
/content/kaggleproject/run_competition.py:234: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  "timestamp": datetime.utcnow().isoformat()

 Competition scan complete!
Found 0 vulnerabilities across 0 categories
Findings saved as findings_*.json files
Summary saved as competition_summary.json